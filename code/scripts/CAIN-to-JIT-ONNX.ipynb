{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CAIN-TO-JIT-ONNX.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPvsTUsNffEc",
        "cellView": "form"
      },
      "source": [
        "#@title CAIN ARCH\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import json\n",
        "\n",
        "def sub_mean(x):\n",
        "    mean = x.mean(2, keepdim=True).mean(3, keepdim=True)\n",
        "    x -= mean\n",
        "    return x, mean\n",
        "\n",
        "def pixel_shuffle(input, scale_factor):\n",
        "    batch_size, channels, in_height, in_width = input.size()\n",
        "\n",
        "    out_channels = int(int(channels / scale_factor) / scale_factor)\n",
        "    out_height = int(in_height * scale_factor)\n",
        "    out_width = int(in_width * scale_factor)\n",
        "\n",
        "    if scale_factor >= 1:\n",
        "        input_view = input.contiguous().view(batch_size, out_channels, scale_factor, scale_factor, in_height, in_width)\n",
        "        shuffle_out = input_view.permute(0, 1, 4, 2, 5, 3).contiguous()\n",
        "    else:\n",
        "        block_size = int(1 / scale_factor)\n",
        "        input_view = input.contiguous().view(batch_size, channels, out_height, block_size, out_width, block_size)\n",
        "        shuffle_out = input_view.permute(0, 1, 3, 5, 2, 4).contiguous()\n",
        "\n",
        "    return shuffle_out.view(batch_size, out_channels, out_height, out_width)\n",
        "\n",
        "\n",
        "class PixelShuffle(nn.Module):\n",
        "    def __init__(self, scale_factor):\n",
        "        super(PixelShuffle, self).__init__()\n",
        "        self.scale_factor = scale_factor\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return pixel_shuffle(x, self.scale_factor)\n",
        "    def extra_repr(self):\n",
        "        return 'scale_factor={}'.format(self.scale_factor)\n",
        "\n",
        "\n",
        "class ConvNorm(nn.Module):\n",
        "    def __init__(self, in_feat, out_feat, kernel_size, stride=1, norm=False):\n",
        "        super(ConvNorm, self).__init__()\n",
        "\n",
        "        reflection_padding = kernel_size // 2\n",
        "        self.reflection_pad = nn.ReflectionPad2d(reflection_padding)\n",
        "        self.conv = nn.Conv2d(in_feat, out_feat, stride=stride, kernel_size=kernel_size, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.reflection_pad(x)\n",
        "        out = self.conv(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class meanShift(nn.Module):\n",
        "    def __init__(self, rgbRange, rgbMean, sign, nChannel=3):\n",
        "        super(meanShift, self).__init__()\n",
        "        if nChannel == 1:\n",
        "            l = rgbMean[0] * rgbRange * float(sign)\n",
        "\n",
        "            self.shifter =  nn.Conv2d(1, 1, kernel_size=1, stride=1, padding=0)\n",
        "            self.shifter.weight.data = torch.eye(1).view(1, 1, 1, 1)\n",
        "            self.shifter.bias.data = torch.Tensor([l])\n",
        "        elif nChannel == 3:  \n",
        "            r = rgbMean[0] * rgbRange * float(sign)\n",
        "            g = rgbMean[1] * rgbRange * float(sign)\n",
        "            b = rgbMean[2] * rgbRange * float(sign)\n",
        "\n",
        "            self.shifter =  nn.Conv2d(3, 3, kernel_size=1, stride=1, padding=0)\n",
        "            self.shifter.weight.data = torch.eye(3).view(3, 3, 1, 1)\n",
        "            self.shifter.bias.data = torch.Tensor([r, g, b])\n",
        "        else:\n",
        "            r = rgbMean[0] * rgbRange * float(sign)\n",
        "            g = rgbMean[1] * rgbRange * float(sign)\n",
        "            b = rgbMean[2] * rgbRange * float(sign)\n",
        "            self.shifter =  nn.Conv2d(6, 6, kernel_size=1, stride=1, padding=0)\n",
        "            self.shifter.weight.data = torch.eye(6).view(6, 6, 1, 1)\n",
        "            self.shifter.bias.data = torch.Tensor([r, g, b, r, g, b])\n",
        "\n",
        "        # Freeze the meanShift layer\n",
        "        for params in self.shifter.parameters():\n",
        "            params.requires_grad = False\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.shifter(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "\"\"\" CONV - (BN) - RELU - CONV - (BN) \"\"\"\n",
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, in_feat, out_feat, kernel_size=3, reduction=False, bias=True, # 'reduction' is just for placeholder\n",
        "                 norm=False, act=nn.ReLU(True), downscale=False):\n",
        "        super(ResBlock, self).__init__()\n",
        "\n",
        "        self.body = nn.Sequential(\n",
        "            ConvNorm(in_feat, out_feat, kernel_size=kernel_size, stride=2 if downscale else 1),\n",
        "            act,\n",
        "            ConvNorm(out_feat, out_feat, kernel_size=kernel_size, stride=1)\n",
        "        )\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        res = x\n",
        "        out = self.body(x)\n",
        "        out += res\n",
        "\n",
        "        return out \n",
        "\n",
        "\n",
        "## Channel Attention (CA) Layer\n",
        "class CALayer(nn.Module):\n",
        "    def __init__(self, channel, reduction=16):\n",
        "        super(CALayer, self).__init__()\n",
        "        # global average pooling: feature --> point\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        # feature channel downscale and upscale --> channel weight\n",
        "        self.conv_du = nn.Sequential(\n",
        "            nn.Conv2d(channel, channel // reduction, 1, padding=0, bias=True),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(channel // reduction, channel, 1, padding=0, bias=True),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.avg_pool(x)\n",
        "        y = self.conv_du(y)\n",
        "        return x * y\n",
        "\n",
        "\n",
        "## Residual Channel Attention Block (RCAB)\n",
        "class RCAB(nn.Module):\n",
        "    def __init__(self, in_feat, out_feat, kernel_size, reduction, bias=True,\n",
        "            norm=False, act=nn.ReLU(True), downscale=False, return_ca=False):\n",
        "        super(RCAB, self).__init__()\n",
        "\n",
        "        self.body = nn.Sequential(\n",
        "            ConvNorm(in_feat, out_feat, kernel_size, stride=1, norm=norm),\n",
        "            act,\n",
        "            ConvNorm(out_feat, out_feat, kernel_size, stride=1, norm=norm),\n",
        "            CALayer(out_feat, reduction)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        res = x\n",
        "        out = self.body(x)\n",
        "        out += res\n",
        "        return out\n",
        "\n",
        "\n",
        "## Residual Group (RG)\n",
        "class ResidualGroup(nn.Module):\n",
        "    def __init__(self, Block, n_resblocks, n_feat, kernel_size, reduction, act, norm=False):\n",
        "        super(ResidualGroup, self).__init__()\n",
        "        modules_body = [Block(n_feat, n_feat, kernel_size, reduction, bias=True, norm=norm, act=act)\n",
        "            for _ in range(n_resblocks)]\n",
        "        modules_body.append(ConvNorm(n_feat, n_feat, kernel_size, stride=1, norm=norm))\n",
        "        self.body = nn.Sequential(*modules_body)\n",
        "\n",
        "    def forward(self, x):\n",
        "        res = self.body(x)\n",
        "        res += x\n",
        "        return res\n",
        "\n",
        "class Interpolation(nn.Module):\n",
        "    def __init__(self, n_resgroups, n_resblocks, n_feats, \n",
        "                 reduction=16, act=nn.LeakyReLU(0.2, True), norm=False):\n",
        "        super(Interpolation, self).__init__()\n",
        "\n",
        "\n",
        "        self.headConv = nn.Conv2d(n_feats*2, n_feats,stride=1,padding=1,bias=True,groups=1,kernel_size=3)\n",
        "        modules_body = [\n",
        "            ResidualGroup(\n",
        "                RCAB,\n",
        "                n_resblocks=12\n",
        "                ,\n",
        "                n_feat=n_feats,\n",
        "                kernel_size=3,\n",
        "                reduction=reduction, \n",
        "                act=act, \n",
        "                norm=norm)\n",
        "            for _ in range(3)]\n",
        "        self.body = nn.Sequential(*modules_body)\n",
        "\n",
        "        self.tailConv = nn.Conv2d(n_feats, n_feats,stride=1,padding=1,bias=True,groups=1,kernel_size=3)\n",
        "\n",
        "    def forward(self, x0, x1):\n",
        "        # Build input tensor\n",
        "        x = torch.cat([x0, x1], dim=1)\n",
        "        x = self.headConv(x)\n",
        "        print(x.shape)\n",
        "        res = self.body(x)\n",
        "        res += x\n",
        "\n",
        "        out = self.tailConv(res)\n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, in_channels=3, depth=3):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.shuffler = PixelShuffle(1 / 2**depth)\n",
        "        relu = nn.LeakyReLU(0.2, True)\n",
        "        self.interpolate = Interpolation(5, 12, in_channels * (4**depth), act=relu)\n",
        "        \n",
        "    def forward(self, x1, x2):\n",
        "        feats1 = self.shuffler(x1)\n",
        "        feats2 = self.shuffler(x2)\n",
        "        feats = self.interpolate(feats1, feats2)\n",
        "        return feats\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, depth=3):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.shuffler = PixelShuffle(2**depth)\n",
        "\n",
        "    def forward(self, feats):\n",
        "        out = self.shuffler(feats)\n",
        "        return out\n",
        "\n",
        "\n",
        "class CAIN(nn.Module):\n",
        "    def __init__(self, depth=3):\n",
        "        super(CAIN, self).__init__()\n",
        "        self.encoder = Encoder(in_channels=3, depth=depth)\n",
        "        self.decoder = Decoder(depth=depth)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x1, m1 = sub_mean(x1)\n",
        "        x2, m2 = sub_mean(x2)\n",
        "        out = self.decoder(self.encoder(x1, x2))\n",
        "        mi = (m1 + m2) / 2\n",
        "        out += mi\n",
        "        return out\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZJfKjEcTrqp"
      },
      "source": [
        "# save at jit\n",
        "model = CAIN(3)\n",
        "model.load_state_dict(torch.load(\"/content/cvpv5_statedict.pth\", map_location=torch.device('cpu')))\n",
        "\n",
        "traced_model = torch.jit.trace(model, (torch.randn(1,3,256,256),torch.randn(1,3,256,256)))\n",
        "torch.jit.save(traced_model, \"/content/output.pt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cd8PZ2MMX61R"
      },
      "source": [
        "# save as onnx\n",
        "import torch\n",
        "batch_size = 4\n",
        "width = 1280\n",
        "height = 720\n",
        "\n",
        "size = (batch_size,3,width, height)\n",
        "dummy_input1 = torch.randn(size)\n",
        "dummy_input2 = torch.randn(size)\n",
        "input_names = [\"input_1\", \"input_2\"]\n",
        "output_names = [\"output_frame\"]\n",
        "model = CAIN(3)\n",
        "model.load_state_dict(torch.load(\"/content/cvpv5_statedict.pth\", map_location=torch.device('cpu')),strict=False)\n",
        "print(\"converting model...\")\n",
        "torch.onnx.export(model, (dummy_input1,dummy_input2), f\"output.onnx\", verbose=False, input_names=input_names, output_names=output_names, dynamic_axes={'input' : {0 : 'batch_size'}, 'input' : {2 : 'height'},'input' : {3 : 'width'},'output' : {0 : 'batch_size'},'output' : {2 : 'height'},'output' : {3 : 'width'}})\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}