{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CAIN-TO-JIT-ONNX.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zrPR9S4X0B6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "CP6kwparXYK1"
      },
      "source": [
        "#@title CAIN ARCH\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import json\n",
        "def sub_mean(x):\n",
        "    mean = x.mean(2, keepdim=True).mean(3, keepdim=True)\n",
        "    x -= mean\n",
        "    return x, mean\n",
        "\n",
        "# https://github.com/fangwei123456/PixelUnshuffle-pytorch/blob/master/PixelUnshuffle/__init__.py\n",
        "def pixel_unshuffle(input, downscale_factor):\n",
        "    '''\n",
        "    input: batchSize * c * k*w * k*h\n",
        "    kdownscale_factor: k\n",
        "    batchSize * c * k*w * k*h -> batchSize * k*k*c * w * h\n",
        "    '''\n",
        "    c = input.shape[1]\n",
        "\n",
        "    kernel = torch.zeros(size=[downscale_factor * downscale_factor * c,\n",
        "                               1, downscale_factor, downscale_factor],\n",
        "                         device=input.device)\n",
        "    for y in range(downscale_factor):\n",
        "        for x in range(downscale_factor):\n",
        "            kernel[x + y * downscale_factor::downscale_factor*downscale_factor, 0, y, x] = 1\n",
        "    return F.conv2d(input, kernel, stride=downscale_factor, groups=c)\n",
        "\n",
        "class PixelUnshuffle(nn.Module):\n",
        "    def __init__(self, downscale_factor):\n",
        "        super(PixelUnshuffle, self).__init__()\n",
        "        self.downscale_factor = downscale_factor\n",
        "    def forward(self, input):\n",
        "        '''\n",
        "        input: batchSize * c * k*w * k*h\n",
        "        kdownscale_factor: k\n",
        "        batchSize * c * k*w * k*h -> batchSize * k*k*c * w * h\n",
        "        '''\n",
        "\n",
        "        return pixel_unshuffle(input, self.downscale_factor)\n",
        "\n",
        "\n",
        "class ConvNorm(nn.Module):\n",
        "    def __init__(self, in_feat, out_feat, kernel_size, stride=1, norm=False):\n",
        "        super(ConvNorm, self).__init__()\n",
        "\n",
        "        reflection_padding = kernel_size // 2\n",
        "        #self.reflection_pad = nn.ReflectionPad2d(reflection_padding)\n",
        "        # because of tensorrt\n",
        "        self.reflection_pad = torch.nn.ZeroPad2d(reflection_padding)\n",
        "        self.conv = nn.Conv2d(in_feat, out_feat, stride=stride, kernel_size=kernel_size, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.reflection_pad(x)\n",
        "        out = self.conv(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class meanShift(nn.Module):\n",
        "    def __init__(self, rgbRange, rgbMean, sign, nChannel=3):\n",
        "        super(meanShift, self).__init__()\n",
        "        if nChannel == 1:\n",
        "            l = rgbMean[0] * rgbRange * float(sign)\n",
        "\n",
        "            self.shifter =  nn.Conv2d(1, 1, kernel_size=1, stride=1, padding=0)\n",
        "            self.shifter.weight.data = torch.eye(1).view(1, 1, 1, 1)\n",
        "            self.shifter.bias.data = torch.Tensor([l])\n",
        "        elif nChannel == 3:  \n",
        "            r = rgbMean[0] * rgbRange * float(sign)\n",
        "            g = rgbMean[1] * rgbRange * float(sign)\n",
        "            b = rgbMean[2] * rgbRange * float(sign)\n",
        "\n",
        "            self.shifter =  nn.Conv2d(3, 3, kernel_size=1, stride=1, padding=0)\n",
        "            self.shifter.weight.data = torch.eye(3).view(3, 3, 1, 1)\n",
        "            self.shifter.bias.data = torch.Tensor([r, g, b])\n",
        "        else:\n",
        "            r = rgbMean[0] * rgbRange * float(sign)\n",
        "            g = rgbMean[1] * rgbRange * float(sign)\n",
        "            b = rgbMean[2] * rgbRange * float(sign)\n",
        "            self.shifter =  nn.Conv2d(6, 6, kernel_size=1, stride=1, padding=0)\n",
        "            self.shifter.weight.data = torch.eye(6).view(6, 6, 1, 1)\n",
        "            self.shifter.bias.data = torch.Tensor([r, g, b, r, g, b])\n",
        "\n",
        "        # Freeze the meanShift layer\n",
        "        for params in self.shifter.parameters():\n",
        "            params.requires_grad = False\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.shifter(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "\"\"\" CONV - (BN) - RELU - CONV - (BN) \"\"\"\n",
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, in_feat, out_feat, kernel_size=3, reduction=False, bias=False, # 'reduction' is just for placeholder\n",
        "                 norm=False, act=nn.ReLU(True), downscale=False):\n",
        "        super(ResBlock, self).__init__()\n",
        "\n",
        "        self.body = nn.Sequential(\n",
        "            ConvNorm(in_feat, out_feat, kernel_size=kernel_size, stride=2 if downscale else 1),\n",
        "            act,\n",
        "            ConvNorm(out_feat, out_feat, kernel_size=kernel_size, stride=1)\n",
        "        )\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        res = x\n",
        "        out = self.body(x)\n",
        "        out += res\n",
        "\n",
        "        return out \n",
        "\n",
        "\n",
        "## Channel Attention (CA) Layer\n",
        "class CALayer(nn.Module):\n",
        "    def __init__(self, channel, reduction=16):\n",
        "        super(CALayer, self).__init__()\n",
        "        # global average pooling: feature --> point\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        # feature channel downscale and upscale --> channel weight\n",
        "        self.conv_du = nn.Sequential(\n",
        "            nn.Conv2d(channel, channel // reduction, 1, padding=0, bias=False),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(channel // reduction, channel, 1, padding=0, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.avg_pool(x)\n",
        "        y = self.conv_du(y)\n",
        "        return x * y\n",
        "\n",
        "\n",
        "## Residual Channel Attention Block (RCAB)\n",
        "class RCAB(nn.Module):\n",
        "    def __init__(self, in_feat, out_feat, kernel_size, reduction, bias=False,\n",
        "            norm=False, act=nn.ReLU(True), downscale=False, return_ca=False):\n",
        "        super(RCAB, self).__init__()\n",
        "\n",
        "        self.body = nn.Sequential(\n",
        "            ConvNorm(in_feat, out_feat, kernel_size, stride=1, norm=norm),\n",
        "            act,\n",
        "            ConvNorm(out_feat, out_feat, kernel_size, stride=1, norm=norm),\n",
        "            CALayer(out_feat, reduction)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        res = x\n",
        "        out = self.body(x)\n",
        "        out += res\n",
        "        return out\n",
        "\n",
        "\n",
        "## Residual Group (RG)\n",
        "class ResidualGroup(nn.Module):\n",
        "    def __init__(self, Block, n_resblocks, n_feat, kernel_size, reduction, act, norm=False):\n",
        "        super(ResidualGroup, self).__init__()\n",
        "        modules_body = [Block(n_feat, n_feat, kernel_size, reduction, bias=False, norm=norm, act=act)\n",
        "            for _ in range(n_resblocks)]\n",
        "        modules_body.append(ConvNorm(n_feat, n_feat, kernel_size, stride=1, norm=norm))\n",
        "        self.body = nn.Sequential(*modules_body)\n",
        "\n",
        "    def forward(self, x):\n",
        "        res = self.body(x)\n",
        "        res += x\n",
        "        return res\n",
        "\n",
        "class Interpolation(nn.Module):\n",
        "    def __init__(self, n_resgroups, n_resblocks, n_feats, \n",
        "                 reduction=16, act=nn.LeakyReLU(0.2, True), norm=False):\n",
        "        super(Interpolation, self).__init__()\n",
        "\n",
        "        self.headConv = nn.Conv2d(n_feats*2, n_feats,stride=1,padding=1,bias=False,groups=1,kernel_size=3)\n",
        "        modules_body = [\n",
        "            ResidualGroup(\n",
        "                RCAB,\n",
        "                n_resblocks=12,\n",
        "                n_feat=n_feats,\n",
        "                kernel_size=3,\n",
        "                reduction=reduction, \n",
        "                act=act, \n",
        "                norm=norm)\n",
        "            for _ in range(2)]\n",
        "        self.body = nn.Sequential(*modules_body)\n",
        "\n",
        "        self.tailConv = nn.Conv2d(n_feats, n_feats,stride=1,padding=1,bias=False,groups=1,kernel_size=3)\n",
        "\n",
        "    def forward(self, x0, x1):\n",
        "        # Build input tensor\n",
        "        x = torch.cat([x0, x1], dim=1)\n",
        "        x = self.headConv(x)\n",
        "\n",
        "        res = self.body(x)\n",
        "        res += x\n",
        "\n",
        "        out = self.tailConv(res)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, in_channels=3, depth=3):\n",
        "        super(Encoder, self).__init__()\n",
        "        #self.shuffler = torch.nn.PixelUnshuffle(2**depth)\n",
        "        # custom unshuffle\n",
        "        self.shuffler = PixelUnshuffle(2**depth)\n",
        "        relu = nn.LeakyReLU(0.2, True)\n",
        "        self.interpolate = Interpolation(5, 12, in_channels * (4**depth), act=relu)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        feats1 = self.shuffler(x1)\n",
        "        feats2 = self.shuffler(x2)\n",
        "        feats = self.interpolate(feats1, feats2)\n",
        "        return feats\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, depth=3):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.shuffler = torch.nn.PixelShuffle(2**depth)\n",
        "\n",
        "    def forward(self, feats):\n",
        "        out = self.shuffler(feats)\n",
        "        return out\n",
        "\n",
        "\n",
        "class CAIN(nn.Module):\n",
        "    def __init__(self, depth=3):\n",
        "        super(CAIN, self).__init__()\n",
        "        self.encoder = Encoder(in_channels=3, depth=depth)\n",
        "        self.decoder = Decoder(depth=depth)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x1, m1 = sub_mean(x1)\n",
        "        x2, m2 = sub_mean(x2)\n",
        "        out = self.decoder(self.encoder(x1, x2))\n",
        "        mi = (m1 + m2) / 2\n",
        "        out += mi\n",
        "        return out\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cd8PZ2MMX61R"
      },
      "source": [
        "# save as onnx\n",
        "import torch\n",
        "batch_size = 4\n",
        "width = 848\n",
        "height = 480\n",
        "\n",
        "size = (batch_size,3, height, width)\n",
        "dummy_input1 = torch.randn(size)\n",
        "dummy_input2 = torch.randn(size)\n",
        "input_names = [\"input_1\", \"input_2\"]\n",
        "output_names = [\"output_frame\"]\n",
        "model = CAIN(3)\n",
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/cvpv5_statedict.pth\", map_location=torch.device('cpu')),strict=False)\n",
        "print(\"converting model...\")\n",
        "torch.onnx.export(model, (dummy_input1,dummy_input2), f\"output.onnx\", verbose=False, opset_version=13, input_names=input_names, output_names=output_names, dynamic_axes={'input' : {0 : 'batch_size'}, 'input' : {2 : 'height'},'input' : {3 : 'width'},'output' : {0 : 'batch_size'},'output' : {2 : 'height'},'output' : {3 : 'width'}})\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZJfKjEcTrqp"
      },
      "source": [
        "# save at jit\n",
        "model = CAIN(3)\n",
        "model.load_state_dict(torch.load(\"/content/cvpv5_statedict.pth\", map_location=torch.device('cpu')))\n",
        "\n",
        "traced_model = torch.jit.trace(model, (torch.randn(1,3,256,256),torch.randn(1,3,256,256)))\n",
        "torch.jit.save(traced_model, \"/content/output.pt\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}